A test process usually consists of the main groups of activities described below. Although many of these activities may appear to follow a logical sequence, they are often implemented iteratively or in parallel. These testing activities usually need to be tailored to the system and the project.

[Test planning](Test%20planning.md) consists of defining the [objectives](Test%20objectives.md) and then selecting an [approach](Test%20approach.md) that best achieves the [objectives](Test%20objectives.md) within the constraints imposed by the overall context. Test planning is further explained in section 5.1.

[Test monitoring](Test%20monitoring.md) and [control](Test%20control.md). Test monitoring involves the ongoing checking of all test activities and the comparison of actual progress against the plan. [Test control](Test%20control.md) involves taking the actions necessary to meet the [objectives of testing](Test%20objectives.md). Test monitoring and control are further explained in section 5.3.

[Test analysis](Test%20analysis.md) includes analysing the test basis to identify testable features and to define and prioritise associated [test conditions](Test%20condition.md), together with the related risks and risk levels (see section 5.2). The test basis and the [test objects](Test%20object.md) are also evaluated to identify [defects](Defect.md) they may contain and to assess their testability. [Test analysis](Test%20analysis.md) is often supported by the use of test techniques (see chapter 4). [Test analysis](Test%20analysis.md) answers the question "what to test?" in terms of measurable coverage criteria.

[Test design](Test%20design.md) includes elaborating the [test conditions](Test%20condition.md) into test cases and other [Testware](Testware.md) (e.g., [test charters](Test%20charter.md)). This activity often involves the identification of coverage items, which serve as a guide to specify test case inputs. Test techniques (see chapter 4) can be used to support this activity. [Test design](Test%20design.md) also includes defining the test data requirements, designing the test environment and identifying any other required infrastructure and tools. Test design answers the question "how to test?".

[Test implementation](Test%20implementation.md) includes creating or acquiring the [Testware](Testware.md) necessary for [Test execution](Test%20execution.md) (e.g., test data). Test cases can be organised into test procedures and are often assembled into test suites. Manual and automated test scripts are created. Test procedures are prioritised and arranged within a test execution schedule for efficient test execution (see section 5.1.5). The [test environment](Test%20environment.md) is built and verified to be set up correctly.

[Test execution](Test%20execution.md) includes running the tests in accordance with the test execution schedule (test runs). Test execution may be manual or automated. Test execution can take many forms, including [continuous testing](Continuous%20testing.md) or pair testing sessions. Actual test results are compared with the expected results. The [test results](Test%20result.md) are logged. Anomalies are analysed to identify their likely causes. This analysis allows us to report the anomalies based on the [failures](Failure.md) observed (see section 5.5).

[Test completion](Test%20completion.md) activities usually occur at project milestones (e.g., release, end of iteration, test level completion) for any unresolved defects, change requests or product backlog items created. Any [Testware](Testware.md) that may be useful in the future is identified and archived or handed over to the appropriate teams. The [test environment](Test%20environment.md) is shut down to an agreed state. The test activities are analysed to identify lessons learned and improvements for future iterations, releases, or projects (see section 2.1.6). A test completion report is created and communicated to the stakeholders.